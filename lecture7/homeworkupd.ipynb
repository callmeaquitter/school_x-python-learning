class Matrix:
    def __init__(self, matrix):
        self.matrix = matrix

    def __add__(self, other):
        result = []
        for i in range(len(self.matrix)):
            row = []
            for j in range(len(self.matrix[0])):
                row.append(self.matrix[i][j] + other.matrix[i][j])
            result.append(row)
        return Matrix(result)
    
    def T(self):
        result = []
        for j in range(len(self.matrix[0])):
            row = []
            for i in range(len(self.matrix)):
                row.append(self.matrix[i][j])
            result.append(row)
        return Matrix(result)

    def __sub__(self, other):
        result = []
        for i in range(len(self.matrix)):
            row = []
            for j in range(len(self.matrix[0])):
                row.append(self.matrix[i][j] - other.matrix[i][j])
            result.append(row)
        return Matrix(result)


    def __truediv__(self, other):
        if isinstance(other, (int, float)):
            result = []
            for i in range(len(self.matrix)):
                row = []
                for j in range(len(self.matrix[0])):
                    row.append(self.matrix[i][j] / other)
                result.append(row)
            return Matrix(result)

    def __mul__(self, other):
        result = []
        for i in range(len(self.matrix)):
            row = []
            for j in range(len(other.matrix[0])):
                sum = 0
                for k in range(len(other.matrix)):
                    sum += self.matrix[i][k] * other.matrix[k][j]
                row.append(sum)
            result.append(row)
        return Matrix(result)
matrix1 = [
    [1, 2],
    [4, 5]
    ]
matrix2 = [
    [5, 6],
    [7, 8]
    ]

my_matrix1 = Matrix(matrix1)
my_matrix2 = Matrix(matrix2)

print(my_matrix1 @ my_matrix2)

print(my_matrix1 + my_matrix2)

print(my_matrix1 * my_matrix2)

print(my_matrix1 / 2)

print(my_matrix1.T())